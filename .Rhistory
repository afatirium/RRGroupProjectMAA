# Drop the "PoolQC" column from the test dataset
test <- test[, !(colnames(test) %in% "PoolQC")]
#########Fill the missing variables for the categorical variables:
# Define the features with missing values
obj_NA <- c("Alley", "BsmtQual", "BsmtCond", "BsmtExposure", "BsmtFinType1",
"BsmtFinType2", "FireplaceQu", "GarageType", "GarageFinish",
"GarageQual", "GarageCond", "Fence", "MiscFeature")
# Fill in missing values with "NA" for the specified features in the train dataset
for (i in obj_NA) {
train[, i][is.na(train[, i])] <- "NA"
}
# Fill in missing values with "NA" for the specified features in the test dataset
for (i in obj_NA) {
test[, i][is.na(test[, i])] <- "NA"
}
# Fill in missing values for the MSZoning, MasVnrType, Electrical, KitchenQual, Functional and SaleType
obj_mode <- c("MSZoning", "MasVnrType", "Electrical", "KitchenQual", "Functional", "SaleType")
train$MSZoning[train$MSZoning == "C (all)"] <- "C"
test$MSZoning[test$MSZoning == "C (all)"] <- "C"
for (i in obj_mode) {
train[[i]][is.na(train[[i]])] <- names(which.max(table(train[[i]])))
test[[i]][is.na(test[[i]])] <- names(which.max(table(test[[i]])))
}
# Fill in missing values for the Utilities feature
test$Utilities[is.na(test$Utilities)] <- "NoSeWa"
# Fill in missing values for the Exterior1st feature
test$Exterior1st[is.na(test$Exterior1st)] <- "ImStucc"
# Fill in missing values for the Exterior2nd feature
test$Exterior2nd[is.na(test$Exterior2nd)] <- "Other"
##Clean continues variables:
##Fill missing variables
# # Fill in missing values for the LotFrontage and MasVnrArea features
obj_median <- c("LotFrontage", "MasVnrArea")
for (i in obj_median) {
train[[i]] <- na.aggregate(train[[i]], FUN = median)
test[[i]] <- na.aggregate(test[[i]], FUN = median)
}
#  Fill in missing values for the BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, BsmtFullBath, BsmtHalfBath, GarageCars and GarageArea features
Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
obj_mode <- c("BsmtFinSF1", "BsmtFinSF2", "BsmtUnfSF", "TotalBsmtSF", "BsmtFullBath", "BsmtHalfBath", "GarageCars", "GarageArea")
for (i in obj_mode) {
test[[i]] <- replace(test[[i]], is.na(test[[i]]), Mode(test[[i]]))
}
# Fill in missing values for the GarageYrBlt feature
train$GarageYrBlt <- ifelse(is.na(train$GarageYrBlt), train$YearBuilt, train$GarageYrBlt)
test$GarageYrBlt <- ifelse(is.na(test$GarageYrBlt), test$YearBuilt, test$GarageYrBlt)
# Converting dtype to 'int64'
int_list <- c("LotFrontage", "BsmtFinSF1", "BsmtFinSF2", "BsmtUnfSF", "TotalBsmtSF", "BsmtFullBath", "BsmtHalfBath", "GarageYrBlt", "GarageCars", "GarageArea")
for (i in int_list) {
train[[i]] <- as.integer(train[[i]])
test[[i]] <- as.integer(test[[i]])
}
#check the shape of dataset
dim(train)
train$LotFrontage <- train$LotFrontage^(1/3)
train$LotArea <- train$LotArea^(1/6)
train$MasVnrArea <- train$MasVnrArea^(1/1.5)
train$BsmtFinSF1 <- train$BsmtFinSF1^(1/1.4)
train$BsmtUnfSF <- train$BsmtUnfSF^(1/1.5)
train$TotalBsmtSF <- train$TotalBsmtSF^(1/1.4)
train$X1stFlrSF <- train$X1stFlrSF^(1/4)
train$GrLivArea <- train$GrLivArea^(1/4.5)
train$GarageArea <- train$GarageArea^(1/1.1)
train$WoodDeckSF <- train$WoodDeckSF^(1/1.2)
train$OpenPorchSF <- train$OpenPorchSF^(1/2.5)
features <- colnames(train)
for (feature in features) {
if (class(train[[feature]]) == "character") {
train[[feature]] <- as.integer(factor(train[[feature]]))
test[[feature]] <- as.integer(factor(test[[feature]]))
}
}
# Drop unnecessary features
X <- train[, !colnames(train) %in% c("SalePrice")]
# Create the target variable
y <- train$SalePrice
# Set the seed for reproducibility
set.seed(42)
# Split the data into training and test sets
train_indices <- sample(1:nrow(train), size = round(0.8 * nrow(train)), replace = FALSE)
X_train <- X[train_indices, ]
y_train <- y[train_indices]
X_test <- X[-train_indices, ]
y_test <- y[-train_indices]
### Standardize Features
# Fit the scaler on the training data
scaler <- scale(X_train)
# Apply the scaler to the training data
X_train_scaled <- scaler
# Apply the scaler to the test data
X_test_scaled <- scale(X_test, center = attr(scaler, "scaled:center"), scale = attr(scaler, "scaled:scale"))
##
# Calculate the mean and standard deviation from the training set
scale_params <- apply(X_train, 2, mean)
scale_sd <- apply(X_train, 2, sd)
# Scale the training set
X_train_scaled <- scale(X_train, center = scale_params, scale = scale_sd)
# Scale the test set using the scaling parameters from the training set
X_test_scaled <- scale(X_test, center = scale_params, scale = scale_sd)
# build finction for loss function
rmse_cv <- function(model) {
rmse <- sqrt(-mean(cross_val_score(model, X, y, scoring = "neg_mean_squared_error", cv = 5)))
return(round(rmse, 4))
}
evaluation <- function(y, predictions) {
mae <- mean(abs(y - predictions))
mse <- mean((y - predictions)^2)
rmse <- sqrt(mse)
r_squared <- 1 - (sum((y - predictions)^2) / sum((y - mean(y))^2))
return(list(mae = round(mae, 4), mse = round(mse, 4), rmse = round(rmse, 4), r_squared = round(r_squared, 4)))
}
models <- data.frame(Model = character(),
MAE = numeric(),
MSE = numeric(),
RMSE = numeric(),
R2_Score = numeric(),
RMSE_CV = numeric(),
stringsAsFactors = FALSE)
# Gradient Boosting Model
# Fit the Gradient Boosting model
g_boost <- gbm(y_train ~ ., data = X_train, n.trees = 100, interaction.depth = 3)
# Predict on the test set
predictions <- predict(g_boost, newdata = X_test, n.trees = 100)
# Calculate evaluation metrics
metrics <- evaluation(y_test, predictions)
mae <- metrics$mae
mse <- metrics$mse
rmse <- metrics$rmse
r_squared <- metrics$r_squared
cat("MAE:", mae, "\n")
cat("MSE:", mse, "\n")
cat("RMSE:", rmse, "\n")
cat("R2 Score:", r_squared, "\n")
cat("----------------------------------\n")
# Perform cross-validation using cv.glmnet
cv_fit <- cv.glmnet(x = as.matrix(X), y = y, nfolds = 5, alpha = 0.5)
# Calculate the RMSE
rmse_cv <- sqrt(cv_fit$cvm)
# Print the RMSE for each fold
cat("RMSE (Cross-Validation):", rmse_cv, "\n")
# Get the average RMSE
mean_rmse_cv <- mean(rmse_cv)
cat("Mean RMSE (Cross-Validation):", mean_rmse_cv, "\n")
# Append the average RMSE to the models data frame
models$`RMSE (Cross-Validation)`[models$Model == "GradientBoosting"] <- mean_rmse_cv
# Create a new row for the model results
new_row <- data.frame(Model = "GradientBoosting",
MAE = mae,
MSE = mse,
RMSE = rmse,
R2_Score = r_squared,
RMSE_CV = mean_rmse_cv)
# Append the new row to the models data frame
models <- rbind(models, new_row)
# Convert the data to DMatrix format
dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
dtest <- xgb.DMatrix(data = as.matrix(X_test))
# Set the parameters for the XGBoost model
params <- list(
objective = "reg:squarederror",
eval_metric = "rmse"
)
# Train the XGBoost model
Xg_boost <- xgb.train(params = params, data = dtrain, nrounds = 100)
# Predict on the test set
predictions <- predict(Xg_boost, newdata = dtest)
# Calculate evaluation metrics
mae <- mean(abs(predictions - y_test))
mse <- mean((predictions - y_test)^2)
rmse <- sqrt(mse)
r_squared <- 1 - mse / var(y_test)
cat("MAE:", mae, "\n")
cat("MSE:", mse, "\n")
cat("RMSE:", rmse, "\n")
cat("R2 Score:", r_squared, "\n")
cat("----------------------------------\n")
# Perform cross-validation to calculate RMSE
cv_result <- xgb.cv(params = params, data = dtrain, nfold = 5, nrounds = 100)
rmse_cross_val <- min(cv_result$evaluation_log$test_rmse_mean)
cat("RMSE Cross-Validation:", rmse_cross_val, "\n")
# Create a new row for the model results
new_row <- data.frame(Model = "XGradientBoosting",
MAE = mae,
MSE = mse,
RMSE = rmse,
R2_Score = r_squared,
RMSE_CV = rmse_cross_val)
# Append the new row to the models data frame
models <- rbind(models, new_row)
models
# Fit the SVR model
svr <- svm(y_train ~ ., data = X_train, kernel = "radial", cost = 100000)
# Predict on the test set
predictions <- predict(svr, newdata = X_test)
# Calculate evaluation metrics
metrics <- evaluation(y_test, predictions)
mae <- metrics$mae
mse <- metrics$mse
rmse <- metrics$rmse
r_squared <- metrics$r_squared
cat("MAE:", mae, "\n")
cat("MSE:", mse, "\n")
cat("RMSE:", rmse, "\n")
cat("R2 Score:", r_squared, "\n")
cat("----------------------------------\n")
# Perform cross-validation to calculate RMSE
library(caret)
# Define the train control with 5-fold cross-validation
ctrl <- trainControl(method = "cv", number = 5)
# Perform cross-validation using train() function
cv_fit <- train(x = as.matrix(X), y = y, method = "svmRadial", trControl = ctrl, preProcess = c("center", "scale"), tuneGrid = data.frame(C = 100000))
# Calculate the RMSE
rmse_cv <- cv_fit$results$RMSE
# Print the RMSE for each fold
cat("RMSE (Cross-Validation):", rmse_cv, "\n")
# Get the average RMSE
mean_rmse_cv <- mean(rmse_cv)
cat("Mean RMSE (Cross-Validation):", mean_rmse_cv, "\n")
# Append the average RMSE to the models data frame
models$`RMSE (Cross-Validation)`[models$Model == "SVR"] <- mean_rmse_cv
# Create a new row for the model results
new_row <- data.frame(Model = "SVR",
MAE = mae,
MSE = mse,
RMSE = rmse,
R2_Score = r_squared,
RMSE_CV = mean_rmse_cv)
# Append the new row to the models data frame
models <- rbind(models, new_row)
# Fit the SVR model
svr <- svm(y_train ~ ., data = X_train, kernel = "radial", cost = 100000)
# Predict on the test set
predictions <- predict(svr, newdata = X_test)
# Calculate evaluation metrics
metrics <- evaluation(y_test, predictions)
mae <- metrics$mae
mse <- metrics$mse
rmse <- metrics$rmse
r_squared <- metrics$r_squared
cat("MAE:", mae, "\n")
cat("MSE:", mse, "\n")
cat("RMSE:", rmse, "\n")
cat("R2 Score:", r_squared, "\n")
cat("----------------------------------\n")
# Perform cross-validation to calculate RMSE
library(caret)
# Define the train control with 5-fold cross-validation
ctrl <- trainControl(method = "cv", number = 5)
# Perform cross-validation using train() function
cv_fit <- train(x = as.matrix(X), y = y, method = "svmRadial", trControl = ctrl, preProcess = c("center", "scale"), tuneGrid = data.frame(C = 100000))
# Calculate the RMSE
rmse_cv <- cv_fit$results$RMSE
# Print the RMSE for each fold
cat("RMSE (Cross-Validation):", rmse_cv, "\n")
# Get the average RMSE
mean_rmse_cv <- mean(rmse_cv)
cat("Mean RMSE (Cross-Validation):", mean_rmse_cv, "\n")
# Append the average RMSE to the models data frame
models$`RMSE (Cross-Validation)`[models$Model == "SVR"] <- mean_rmse_cv
# Create a new row for the model results
new_row <- data.frame(Model = "SVR",
MAE = mae,
MSE = mse,
RMSE = rmse,
R2_Score = r_squared,
RMSE_CV = mean_rmse_cv)
# Append the new row to the models data frame
models <- rbind(models, new_row)
models
### Support Vector Regression (SVR Model)
# Training the SVR model
svr <- SVR(C = 100000)
svr.fit(X_train, y_train)
### Support Vector Regression (SVR Model)
install.packages("e1071")
install.packages("e1071")
library(e1071)
# Training the SVR model
svr <- svm(y_train ~ ., data = X_train, kernel = "radial", cost = 100000)
# Making predictions
predictions <- predict(svr, newdata = X_test)
# Evaluating the model
mae <- mean(abs(predictions - y_test))
mse <- mean((predictions - y_test)^2)
rmse <- sqrt(mse)
r_squared <- 1 - sum((y_test - predictions)^2) / sum((y_test - mean(y_test))^2)
print("MAE:", mae)
print("MSE:", mse)
print("RMSE:", rmse)
# Training the SVR model
svr <- svm(y_train ~ ., data = X_train, kernel = "radial", cost = 100000)
# Making predictions
predictions <- predict(svr, newdata = X_test)
# Evaluating the model
mae <- mean(abs(predictions - y_test))
mse <- mean((predictions - y_test)^2)
rmse <- sqrt(mse)
r_squared <- 1 - sum((y_test - predictions)^2) / sum((y_test - mean(y_test))^2)
cat("MAE:", as.character(mae), "\n")
cat("MSE:", as.character(mse), "\n")
cat("RMSE:", as.character(rmse), "\n")
cat("R2 Score:", as.character(r_squared), "\n")
cat("-" * 30, "\n")
# Calculating RMSE through cross-validation
rmse_cross_val <- sqrt(crossprod(y_train - predict(svr, newdata = X_train)) / length(y_train))
cat(paste(rep("-", 30), collapse = ""), "\n")
# Calculating RMSE through cross-validation
rmse_cross_val <- sqrt(crossprod(y_train - predict(svr, newdata = X_train)) / length(y_train))
cat("RMSE Cross-Validation:", as.character(rmse_cross_val), "\n")
# Creating a new row with the evaluation metrics
new_row <- data.frame(
Model = "SVR",
MAE = mae,
MSE = mse,
RMSE = rmse,
R2_Score = r_squared,
RMSE_Cross_Validation = rmse_cross_val
)
# Appending the new row to the models dataframe
models <- rbind(models, new_row)
models
# Creating a new row with the evaluation metrics
new_row <- data.frame(
Model = "SVR",
MAE = mae,
MSE = mse,
RMSE = rmse,
R2_Score = r_squared,
RMSE_CV = rmse_cross_val
)
# Appending the new row to the models dataframe
models <- rbind(models, new_row)
models
models
# Fit the SVR model
svr <- svm(X_train, y_train, kernel = "radial", cost = 100000)
# Predict on the test set
predictions <- predict(svr, X_test)
# Calculate evaluation metrics
mae <- mean(abs(predictions - y_test))
mse <- mean((predictions - y_test)^2)
rmse <- sqrt(mse)
r_squared <- 1 - mse / var(y_test)
cat("MAE:", mae, "\n")
cat("MSE:", mse, "\n")
cat("RMSE:", rmse, "\n")
cat("R2 Score:", r_squared, "\n")
cat("----------------------------------\n")
# Perform cross-validation to calculate RMSE
install.packages("caret", dependencies = TRUE)
update.packages()
library(caret)
# Define the train control with 5-fold cross-validation
ctrl <- trainControl(method = "cv", number = 5)
library(caret)
# Define the train control with 5-fold cross-validation
ctrl <- trainControl(method = "cv", number = 5)
##Import libraries
library(beanplot)
##Import libraries
library(beanplot)
library(summarytools)
library(ggplot2)
library(summarytools)
library(ggplot2)
library(tidyr)
library(gridExtra)
library(scales)
library(zoo)
library(dplyr)
library(gbm)
library(glmnet)
library(xgboost)
library(e1071)
#setwd('C:\\Users\\Afat\\Documents\\GitHub\\RRGroupProjectMAA') #Afet add setwd for herself
train <- read.csv("train.csv", h=T)
test <- read.csv("test.csv", h=T)
row.names(train) <- train$Id
train$Id <- NULL
row.names(test) <- test$Id
test$Id <- NULL
par(mfrow = c(2, 2))
par(mar = c(4, 4, 2, 1)) # Adjusting the margins for better visualization
# Subplot 1
hist(train$SalePrice, breaks = 50, main = "Sales Price Distribution", xlab = "Sale Price",
ylab = "Counts", col = "lightblue", border = "white")
abline(v = mean(train$SalePrice), lty = 2, col = "red", lwd = 2)
abline(v = median(train$SalePrice), lty = 3, col = "green", lwd = 2)
legend("topright", legend = c("Mean", "Median"), lty = c(2, 3), col = c("red", "green"))
# Subplot 2
plot(train$SalePrice, rnorm(nrow(train), mean = 7, sd = 0.2), main = "Sales Price Distribution",
xlab = "Sale Price", ylab = "Random Values", pch = 16, col = "blue", cex = 0.6)
# Subplot 3
boxplot(train$SalePrice, main = "Sales Price Distribution", ylab = "Sale Price",
col = "lightgreen")
beanplot(train$SalePrice, main = "Sales Price Distribution", ylab = "Sale Price",
col = "lightpink", what = c(1, 1, 0, 0), bw = 0.2)
## 2. Investigate Data Types
str(train)
# Explore the categorical variables
cat_vars <- names(train)[sapply(train, is.character)]
cat_vars
cat_vars <- c(cat_vars, "MSSubClass")
cat_vars
length(cat_vars)
train[cat_vars] <- lapply(train[cat_vars], as.character)
t(sapply(train[cat_vars], summary))
## Summary for categorical variables
dfSummary(train[cat_vars])
#Explore the continues variables, adding summary statistic for continues variables
stat_cont <- summary(train[, sapply(train, is.numeric)])
stat_cont
tr_cont <- train[, !sapply(train, is.character)]
head(tr_cont)
corr <- cor(tr_cont)
melted_corr <- as.data.frame(as.table(corr))
colnames(melted_corr) <- c("Var1", "Var2", "value")
# Increase the plot size
options(repr.plot.width = 30, repr.plot.height = 30)
ggplot(melted_corr, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +  # Set the tile border color to white
scale_fill_gradient(low = "red", high = "yellow") +
labs(title = "Correlation Heatmap") +
theme(axis.text.x = element_text(angle = 90, hjust = 1),  # Rotate x-axis labels
panel.grid = element_blank())  # Remove grid lines
# Select continuous features to plot
features <- names(tr_cont)[!(names(tr_cont) %in% c("Id", "OverallQual", "OverallCond", "YearBuilt", "YearRemodAdd",
"BsmtFullBath", "BsmtHalfBath", "FullBath", "HalfBath",
"BedroomAbvGr", "KitchenAbvGr", "TotRmsAbvGrd", "Fireplaces",
"GarageYrBlt", "GarageCars", "MoSold", "YrSold", "SalePrice"))]
for (i in 1:length(features)) {
hist(tr_cont[[features[i]]], main = paste("Histogram for", features[i]), xlab = features[i], col ="lightblue")
}
######## Missing values
# Check the missing values for train dataset
missing_values <- colSums(is.na(train))
missing_values <- missing_values[order(-missing_values)]
# Display the top 20 variables with the highest number of missing values
head(missing_values, 20)
# Check the missing values for test dataset
missing_values <- colSums(is.na(test))
missing_values <- missing_values[order(-missing_values)]
# Display the top 35 variables with the highest number of missing values
head(missing_values, 35)
# Drop the "PoolQC" column from the train dataset
train <- train[, !(colnames(train) %in% "PoolQC")]
# Drop the "PoolQC" column from the test dataset
test <- test[, !(colnames(test) %in% "PoolQC")]
# Define the features with missing values
obj_NA <- c("Alley", "BsmtQual", "BsmtCond", "BsmtExposure", "BsmtFinType1",
"BsmtFinType2", "FireplaceQu", "GarageType", "GarageFinish",
"GarageQual", "GarageCond", "Fence", "MiscFeature")
# Fill in missing values with "NA" for the specified features in the train dataset
for (i in obj_NA) {
train[, i][is.na(train[, i])] <- "NA"
}
# Fill in missing values with "NA" for the specified features in the test dataset
for (i in obj_NA) {
test[, i][is.na(test[, i])] <- "NA"
}
# Fill in missing values for the MSZoning, MasVnrType, Electrical, KitchenQual, Functional and SaleType
obj_mode <- c("MSZoning", "MasVnrType", "Electrical", "KitchenQual", "Functional", "SaleType")
train$MSZoning[train$MSZoning == "C (all)"] <- "C"
test$MSZoning[test$MSZoning == "C (all)"] <- "C"
for (i in obj_mode) {
train[[i]][is.na(train[[i]])] <- names(which.max(table(train[[i]])))
test[[i]][is.na(test[[i]])] <- names(which.max(table(test[[i]])))
}
# Fill in missing values for the Utilities feature
test$Utilities[is.na(test$Utilities)] <- "NoSeWa"
# Fill in missing values for the Exterior1st feature
test$Exterior1st[is.na(test$Exterior1st)] <- "ImStucc"
# Fill in missing values for the Exterior2nd feature
test$Exterior2nd[is.na(test$Exterior2nd)] <- "Other"
obj_median <- c("LotFrontage", "MasVnrArea")
for (i in obj_median) {
train[[i]] <- na.aggregate(train[[i]], FUN = median)
test[[i]] <- na.aggregate(test[[i]], FUN = median)
}
#  Fill in missing values for the BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, BsmtFullBath, BsmtHalfBath, GarageCars and GarageArea features
Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
obj_mode <- c("BsmtFinSF1", "BsmtFinSF2", "BsmtUnfSF", "TotalBsmtSF", "BsmtFullBath", "BsmtHalfBath", "GarageCars", "GarageArea")
for (i in obj_mode) {
test[[i]] <- replace(test[[i]], is.na(test[[i]]), Mode(test[[i]]))
}
# Fill in missing values for the GarageYrBlt feature
train$GarageYrBlt <- ifelse(is.na(train$GarageYrBlt), train$YearBuilt, train$GarageYrBlt)
test$GarageYrBlt <- ifelse(is.na(test$GarageYrBlt), test$YearBuilt, test$GarageYrBlt)
# Converting dtype to 'int64'
int_list <- c("LotFrontage", "BsmtFinSF1", "BsmtFinSF2", "BsmtUnfSF", "TotalBsmtSF", "BsmtFullBath", "BsmtHalfBath", "GarageYrBlt", "GarageCars", "GarageArea")
for (i in int_list) {
train[[i]] <- as.integer(train[[i]])
test[[i]] <- as.integer(test[[i]])
}
#check the shape of dataset
dim(train)
# Filter numeric variables
numeric_vars <- sapply(train, is.numeric)
# Calculate correlation matrix
correlations <- cor(train[, numeric_vars])
# Sort correlations with 'SalePrice'
sorted_correlations <- sort(correlations[,"SalePrice"], decreasing = TRUE)
# Display the most positive correlations
cat("Most Positive Correlations:\n")
getwd(0)
getwd()
